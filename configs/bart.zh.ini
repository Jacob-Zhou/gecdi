[model]
encoder = 'bart'
bart = 'fnlp/bart-large-chinese'
n_embed = 1024
token_dropout = .2
dropout = .1
encoder_dropout = .0
decoder_dropout = .0
beam_size = 12
max_len = 1024
length_penalty = 1.
topk = 1
find_unused_parameters = 0

[optim]
lr = 3e-06
mu = .9
nu = .999
eps = 1e-8
weight_decay = 0.0
clip = 1.
min_freq = 2
fix_len = 20
warmup_steps = 2000
update_steps = 5
epochs = 60
patience = 3
batch_size = 16384
label_smoothing = 0.1
